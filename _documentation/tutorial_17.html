<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>Surrogate-Based Optimisation with Polynomials &#8212;   v8.1 documentation</title>
    <link rel="stylesheet" href="../_static/bootstrap-sphinx.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="../_static/language_data.js"></script>
    <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="shortcut icon" href="../_static/logo.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="prev" title="Embedded Ridge Approximations" href="tutorial_16.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">
<script type="text/javascript" src="../_static/js/jquery-1.11.0.min.js "></script>
<script type="text/javascript" src="../_static/js/jquery-fix.js "></script>
<script type="text/javascript" src="../_static/bootstrap-3.3.7/js/bootstrap.min.js "></script>
<script type="text/javascript" src="../_static/bootstrap-sphinx.js "></script>

  </head><body>

  <div id="navbar" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="index.html"><span><img src="../_static/logo_white_font.png"></span>
           </a>
        <span class="navbar-text navbar-version pull-left"><b>8.1</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="index.html">Explore <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"><ul class="current">
<li class="toctree-l1"><a class="reference internal" href="introduction.html">Effective Quadratures</a><ul>
<li class="toctree-l2"><a class="reference internal" href="introduction.html#code">Code</a></li>
<li class="toctree-l2"><a class="reference internal" href="introduction.html#workshops">Workshops</a></li>
<li class="toctree-l2"><a class="reference internal" href="introduction.html#papers-theory-and-applications">Papers (theory and applications)</a></li>
<li class="toctree-l2"><a class="reference internal" href="introduction.html#get-in-touch">Get in touch</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="team.html">About us</a></li>
<li class="toctree-l1"><a class="reference internal" href="modules.html">Modules</a><ul>
<li class="toctree-l2"><a class="reference internal" href="parameter.html">Parameter</a></li>
<li class="toctree-l2"><a class="reference internal" href="basis.html">Basis</a></li>
<li class="toctree-l2"><a class="reference internal" href="poly.html">Polynomial</a></li>
<li class="toctree-l2"><a class="reference internal" href="subspaces.html">Dimension reduction with polynomials</a></li>
<li class="toctree-l2"><a class="reference internal" href="optimisation.html">Optimisation with polynomials</a></li>
<li class="toctree-l2"><a class="reference internal" href="polynet.html">Deep learning with polynomials</a></li>
<li class="toctree-l2"><a class="reference internal" href="correlated.html">Correlation mapping for polynomials</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="tutorials.html">Tutorials</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="tutorial_1.html">Defining a parameter</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorial_2.html">Generating univariate quadrature rules</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorial_3.html">Constructing orthogonal polynomials</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorial_4.html">Computing moments</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorial_4b.html">Multi-index sets</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorial_5.html">Sparse and tensor grid quadrature rules</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorial_6a.html">Polynomial regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorial_6.html">Polynomial regression for time varying data</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorial_7.html">Polynomial least squares approximations</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorial_8.html">Polynomials via compressive sensing</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorial_9.html">Computing Sobol’ (sensitivity) indices</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorial_9b.html">Higher order Sobol’ indices</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorial_10.html">Nataf transform for correlated inputs</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorial_11.html">Active subspaces with polynomial approximations</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorial_12.html">Polynomial variable projection</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorial_14.html">Vector-valued dimension reduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorial_15.html">Deep learning via polynomials</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorial_16.html">Embedded Ridge Approximations</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Surrogate-Based Optimisation with Polynomials</a></li>
</ul>
</li>
</ul>
</ul>
</li>
              
            
            
            
            
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="../search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
    <div class="body col-md-12 content" role="main">
      
  <div class="section" id="surrogate-based-optimisation-with-polynomials">
<h1>Surrogate-Based Optimisation with Polynomials<a class="headerlink" href="#surrogate-based-optimisation-with-polynomials" title="Permalink to this headline">¶</a></h1>
<p>In this tutorial, we demonstrate how one may use orthogonal polynomials constructed in Effective Quadratures for surrogate-based optimisation. One particularly significant benefit of using orthogonal polynomials for optimisation is that the polynomial basis terms <span class="math notranslate nohighlight">\(\psi_{i}\)</span> and their derivatives <span class="math notranslate nohighlight">\(\psi_{i}^{(d)}\)</span> may be easily found using the standard four-term recurrence</p>
<div class="math notranslate nohighlight">
\[\sqrt{\beta_{i+1}} \psi_{i+1}^{(d)} = (r-\alpha_i) \psi_i^{(d)} - \sqrt{\beta_i} \psi_{i-1}^{(d)} + d \psi_i^{(d-1)}\]</div>
<p>for <span class="math notranslate nohighlight">\(d,i \geq 0\)</span> where <span class="math notranslate nohighlight">\(\psi_i^{(d)} \equiv 0\)</span> for <span class="math notranslate nohighlight">\(n &lt; d, n &lt; 0\)</span>. The recurrence coefficients <span class="math notranslate nohighlight">\(\alpha_i, \beta_i\)</span>, whose values are determined by the user-specified distribution of the weight function, indicate the class of orthogonal polynomial <span class="math notranslate nohighlight">\(\psi_{i}\)</span>. Using this recurrence relation, derivatives of all orders may be calculated by Effective Quadratures very efficiently, allowing the user to have easy access to gradient information for optimisation of orthogonal polynomials. Effective Quadratures has a built-in <code class="code docutils literal notranslate"><span class="pre">Optimisation</span></code> class that will calculate derivatives of orthogonal polynomials and perform optimisation using the <a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html">minimize</a> method from <a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/optimize.html">Scipy optimize</a>. Also included in this class is a simple derivative-free trust-region method for bound-constrained optimisation of nonlinear functions. This trust-region implementation constructs interpolating quadratic models using a set of <span class="math notranslate nohighlight">\(\frac{(n+1)(n+1)}{2}\)</span> points.</p>
<p>To demonstrate a simple example of how this class can be used for surrogate-based optimisation, we consider the following constrained optimisation problem:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{eqnarray}
\min_{x,y}      \quad           &amp; (1-x)^2 + 100(y-x^2)^2        \\
\textrm{ subject to }   &amp; x^3 - y \leq 0        \\
                                                &amp; x + y = 2                             \\
                                                &amp; -1 \leq x \leq 1                      \\
                                                &amp; -1 \leq y \leq 1.
\end{eqnarray}\end{split}\]</div>
<p>First, let’s use <code class="code docutils literal notranslate"><span class="pre">Poly</span></code> to construct the objective function and the first constraint in terms of Legendre polynomials defined over a total order basis.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">scipy</span> <span class="k">as</span> <span class="nn">sp</span>
<span class="kn">import</span> <span class="nn">equadratures</span> <span class="k">as</span> <span class="nn">eq</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="k">import</span> <span class="n">linregress</span>

<span class="k">def</span> <span class="nf">ObjFun</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">f</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="n">f</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">optimize</span><span class="o">.</span><span class="n">rosen</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">,:])</span>
    <span class="k">return</span> <span class="n">f</span>

<span class="k">def</span> <span class="nf">ConFun1</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">g1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">g1</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="n">g1</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">**</span><span class="mi">3</span> <span class="o">-</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">g1</span>

<span class="n">n</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">20</span>

<span class="c1">#Evaluate the objective and constraint functions over a random DOE</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span>
<span class="n">f</span> <span class="o">=</span> <span class="n">ObjFun</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">g1</span> <span class="o">=</span> <span class="n">ConFun1</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="c1">#Split data into training and testing data</span>
<span class="n">indices</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">))</span>
<span class="n">num_training_instances</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mf">0.8</span> <span class="o">*</span> <span class="n">N</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>
<span class="n">train_indices</span> <span class="o">=</span> <span class="n">indices</span><span class="p">[:</span><span class="n">num_training_instances</span><span class="p">]</span>
<span class="n">test_indices</span> <span class="o">=</span> <span class="n">indices</span><span class="p">[</span><span class="n">num_training_instances</span><span class="p">:]</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">f_train</span><span class="p">,</span> <span class="n">g1_train</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">train_indices</span><span class="p">,</span> <span class="p">:],</span> <span class="n">f</span><span class="p">[</span><span class="n">train_indices</span><span class="p">],</span> <span class="n">g1</span><span class="p">[</span><span class="n">train_indices</span><span class="p">]</span>
<span class="n">X_test</span><span class="p">,</span> <span class="n">f_test</span><span class="p">,</span> <span class="n">g1_test</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">test_indices</span><span class="p">,</span> <span class="p">:],</span> <span class="n">f</span><span class="p">[</span><span class="n">test_indices</span><span class="p">],</span> <span class="n">g1</span><span class="p">[</span><span class="n">test_indices</span><span class="p">]</span>
<span class="c1">#Construct f using Legendre polynomials with a total order basis</span>
<span class="n">fParameters</span> <span class="o">=</span> <span class="p">[</span><span class="n">eq</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">distribution</span><span class="o">=</span><span class="s1">&#39;uniform&#39;</span><span class="p">,</span> <span class="n">lower</span><span class="o">=-</span><span class="mf">1.</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)]</span>
<span class="n">myBasis</span> <span class="o">=</span> <span class="n">eq</span><span class="o">.</span><span class="n">Basis</span><span class="p">(</span><span class="s1">&#39;total-order&#39;</span><span class="p">)</span>
<span class="n">fpoly</span> <span class="o">=</span> <span class="n">eq</span><span class="o">.</span><span class="n">Poly</span><span class="p">(</span><span class="n">fParameters</span><span class="p">,</span> <span class="n">myBasis</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;least-squares&#39;</span><span class="p">,</span> <span class="n">sampling_args</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;mesh&#39;</span><span class="p">:</span> <span class="s1">&#39;user-defined&#39;</span><span class="p">,</span> <span class="s1">&#39;sample-points&#39;</span><span class="p">:</span><span class="n">X_train</span><span class="p">,</span> <span class="s1">&#39;sample-outputs&#39;</span><span class="p">:</span><span class="n">f_train</span><span class="p">})</span>
<span class="n">fpoly</span><span class="o">.</span><span class="n">set_model</span><span class="p">()</span>
<span class="c1">#Construct g1 using Legendre polynomials with a total order basis</span>
<span class="n">g1Parameters</span> <span class="o">=</span> <span class="p">[</span><span class="n">eq</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">distribution</span><span class="o">=</span><span class="s1">&#39;uniform&#39;</span><span class="p">,</span> <span class="n">lower</span><span class="o">=-</span><span class="mf">1.</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)]</span>
<span class="n">myBasis</span> <span class="o">=</span> <span class="n">eq</span><span class="o">.</span><span class="n">Basis</span><span class="p">(</span><span class="s1">&#39;total-order&#39;</span><span class="p">)</span>
<span class="n">g1poly</span> <span class="o">=</span> <span class="n">eq</span><span class="o">.</span><span class="n">Poly</span><span class="p">(</span><span class="n">g1Parameters</span><span class="p">,</span> <span class="n">myBasis</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;least-squares&#39;</span><span class="p">,</span> <span class="n">sampling_args</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;mesh&#39;</span><span class="p">:</span> <span class="s1">&#39;user-defined&#39;</span><span class="p">,</span> <span class="s1">&#39;sample-points&#39;</span><span class="p">:</span><span class="n">X_train</span><span class="p">,</span> <span class="s1">&#39;sample-outputs&#39;</span><span class="p">:</span><span class="n">g1_train</span><span class="p">})</span>
<span class="n">g1poly</span><span class="o">.</span><span class="n">set_model</span><span class="p">()</span>
</pre></div>
</div>
<p>The coefficient of determination (R-squared) value of the fit of both of these functions can be computed via:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">_</span><span class="p">,</span><span class="n">_</span><span class="p">,</span><span class="n">r_f</span><span class="p">,</span><span class="n">_</span><span class="p">,</span><span class="n">_</span> <span class="o">=</span> <span class="n">linregress</span><span class="p">(</span><span class="n">fpoly</span><span class="o">.</span><span class="n">get_polyfit</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">f_test</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
<span class="n">_</span><span class="p">,</span><span class="n">_</span><span class="p">,</span><span class="n">r_g1</span><span class="p">,</span><span class="n">_</span><span class="p">,</span><span class="n">_</span> <span class="o">=</span> <span class="n">linregress</span><span class="p">(</span><span class="n">g1poly</span><span class="o">.</span><span class="n">get_polyfit</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">g1_test</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="n">r_f</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">r_g1</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
<p>Both of these functions very nearly give a fit of <span class="math notranslate nohighlight">\(1.0\)</span>, indicating an almost exact fit.</p>
<div class="figure align-center" id="id1">
<a class="reference internal image-reference" href="../_images/Rosenbrock.png"><img alt="../_images/Rosenbrock.png" src="../_images/Rosenbrock.png" style="width: 581.4px; height: 386.4px;" /></a>
<p class="caption"><span class="caption-text">Figure. Contours of the objective function.</span><a class="headerlink" href="#id1" title="Permalink to this image">¶</a></p>
</div>
<p>Now that the nonlinear functions have been constructed using orthogonal polynomials, we can use <code class="code docutils literal notranslate"><span class="pre">Optimisation</span></code> to solve the aforementioned optimisation problem.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#Initialise optimisation problem by specifying optimisation method</span>
<span class="n">Opt</span> <span class="o">=</span> <span class="n">eq</span><span class="o">.</span><span class="n">Optimisation</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;trust-constr&#39;</span><span class="p">)</span>
<span class="c1">#Add objective function by specifying Poly object</span>
<span class="n">Opt</span><span class="o">.</span><span class="n">add_objective</span><span class="p">(</span><span class="n">poly</span><span class="o">=</span><span class="n">fpoly</span><span class="p">)</span>
<span class="c1">#Add nonlinear inequality constraints lb &lt;= g1poly &lt;= ub</span>
<span class="n">Opt</span><span class="o">.</span><span class="n">add_nonlinear_ineq_con</span><span class="p">(</span><span class="n">poly</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;poly&#39;</span><span class="p">:</span> <span class="n">g1poly</span><span class="p">,</span> <span class="s1">&#39;bounds&#39;</span><span class="p">:</span> <span class="p">[</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">]})</span>
<span class="c1">#Add linear equality constraints Ax = b</span>
<span class="n">Opt</span><span class="o">.</span><span class="n">add_linear_eq_con</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">]),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">2.0</span><span class="p">]))</span>
<span class="c1">#Add lower and upper bounds</span>
<span class="n">Opt</span><span class="o">.</span><span class="n">add_bounds</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n</span><span class="p">))</span>
<span class="c1">#Initialise starting point</span>
<span class="n">x0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
<span class="c1">#Solve optimisation problem</span>
<span class="n">sol</span> <span class="o">=</span> <span class="n">Opt</span><span class="o">.</span><span class="n">optimise</span><span class="p">(</span><span class="n">x0</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">sol</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sol</span><span class="p">[</span><span class="s1">&#39;fun&#39;</span><span class="p">])</span>
</pre></div>
</div>
<p>The solution to the above surrogate-based optimisation problem is dependent on the points which are used to train the model. However, the solution will very closely responds to the true optimal solution of <span class="math notranslate nohighlight">\(0\)</span> found at <span class="math notranslate nohighlight">\(x = [1,1]\)</span>.</p>
<p>Alternatively, if one already has access to function and derivatives values for a quantity of interest, one may not need to construct a <code class="code docutils literal notranslate"><span class="pre">Poly</span></code> object for the function. In these cases, user-provided functions may be supplied to the optimisation routine. The following code demonstrates how to do this for the first constraint of the same optimisation problem.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">ConFun1_Deriv</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">3.0</span><span class="o">*</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">])</span>

<span class="k">def</span> <span class="nf">ConFun1_Hess</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">g_Hess</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
    <span class="n">g_Hess</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mf">6.0</span><span class="o">*</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">g_Hess</span>

<span class="c1">#Construct lambda functions of the constraint, its derivative, and its Hessian</span>
<span class="n">g1Func</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="o">-</span><span class="n">ConFun1</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
<span class="n">g1Grad</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="o">-</span><span class="n">ConFun1_Deriv</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
<span class="n">g1Hess</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="o">-</span><span class="n">ConFun1_Hess</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
<span class="c1">#Initialise optimisation problem by specifying optimization method</span>
<span class="n">Opt</span> <span class="o">=</span> <span class="n">eq</span><span class="o">.</span><span class="n">Optimisation</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;trust-constr&#39;</span><span class="p">)</span>
<span class="c1">#Add objective function by specifying Poly object</span>
<span class="n">Opt</span><span class="o">.</span><span class="n">add_objective</span><span class="p">(</span><span class="n">poly</span><span class="o">=</span><span class="n">fpoly</span><span class="p">)</span>
<span class="c1">#Add lower and upper bounds</span>
<span class="n">Opt</span><span class="o">.</span><span class="n">add_bounds</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n</span><span class="p">))</span>
<span class="c1">#Add linear equality constraints Ax = b</span>
<span class="n">Opt</span><span class="o">.</span><span class="n">add_linear_eq_con</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">2.0</span><span class="p">]))</span>
<span class="c1">#Add nonlinear inequality constraints lb &lt;= g1Func &lt;= ub</span>
<span class="n">Opt</span><span class="o">.</span><span class="n">add_nonlinear_ineq_con</span><span class="p">(</span><span class="n">custom</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;function&#39;</span><span class="p">:</span> <span class="n">g1Func</span><span class="p">,</span> <span class="s1">&#39;jac_function&#39;</span><span class="p">:</span> <span class="n">g1Grad</span><span class="p">,</span> <span class="s1">&#39;hessFunction&#39;</span><span class="p">:</span> <span class="n">g1Hess</span><span class="p">})</span>
<span class="c1">#Initialize starting point</span>
<span class="n">x0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
<span class="c1">#Solve optimisation problem</span>
<span class="n">sol</span> <span class="o">=</span> <span class="n">Opt</span><span class="o">.</span><span class="n">optimise</span><span class="p">(</span><span class="n">x0</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">sol</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sol</span><span class="p">[</span><span class="s1">&#39;fun&#39;</span><span class="p">])</span>
</pre></div>
</div>
<p>Just as in the previous case, the returned solution is dependent on the sample points, but it will be very close to the true optimal solution of <span class="math notranslate nohighlight">\(0\)</span> found at <span class="math notranslate nohighlight">\(x = [1,1]\)</span>.</p>
<p>The main benefit of using Effective Quadratures for optimisation is best realized in cases where derivatives are not known a priori or are very expensive to calculate. Such situations are commonplace in the scientific community e.g. for ‘black-box’ functions whose values are obtained through the use of expensive computer simulations. Derivative-free optimisation strategies, such as stochastic optimisation or Bayesian optimisation, may be used in such situations; however, these methods may not scale very well for problems of moderate to high dimension. On the other hand, using techniques available within Effective Quadratures, one can readily construct surrogate models of the function of interest using orthogonal polynomials and then optimise over the surrogate to approximate the optimal solution, even for high-dimensional functions.</p>
<p>To demonstrate this, we consider the following constrained optimisation problem:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{eqnarray}
\min_{\mathbf{x}}       \quad           &amp; \sum_{i=1}^n 3x_i^2 + 2x_i    \\
\textrm{ subject to }   &amp; \mathbf{x}^T \mathbf{x} \leq 4.
\end{eqnarray}\end{split}\]</div>
<p>Although, the gradients of these functions can be easily calculated analytically, we will show that if <a class="reference external" href="https://en.wikipedia.org/wiki/COBYLA">COBYLA</a> (a very common derivative-free optimisation strategy) is used, the number of function evaluations can be prohibitively high.</p>
<p>The new objective and constraint can be defined using the following:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">ObjFun2</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">f</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="n">f</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mf">3.0</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">,:],</span> <span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="mf">2.0</span><span class="o">*</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">,:])</span>
    <span class="k">return</span> <span class="n">f</span>

<span class="k">def</span> <span class="nf">ConFun2</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">g</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="n">g</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">,:],</span><span class="mi">2</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">g</span>
</pre></div>
</div>
<p>We call SciPy implementation of COBYLA using the following code:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">constraints</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="s1">&#39;ineq&#39;</span><span class="p">,</span> <span class="s1">&#39;fun&#39;</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">ConFun2</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span> <span class="o">-</span> <span class="mf">4.0</span><span class="p">}</span>
<span class="n">sol</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">optimize</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">ObjFun2</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)),</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">),</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;COBYLA&#39;</span><span class="p">,</span> <span class="n">constraints</span><span class="o">=</span><span class="n">constraints</span><span class="p">)</span>
<span class="n">xopt</span> <span class="o">=</span> <span class="n">sol</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">ObjFun2</span><span class="p">(</span><span class="n">xopt</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">ConFun2</span><span class="p">(</span><span class="n">xopt</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sol</span><span class="p">[</span><span class="s1">&#39;nfev&#39;</span><span class="p">])</span>
</pre></div>
</div>
<p>On the other hand, both of these functions are sparse (i.e. most of the polynomial coefficients are zero), so we can use the <code class="code docutils literal notranslate"><span class="pre">compressive-sensing</span></code> method within Effective Quadratures to construct accurate surrogates and perform surrogate-based optimisation using the following code:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">n</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">150</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span>
<span class="n">f</span> <span class="o">=</span> <span class="n">ObjFun2</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">g2</span> <span class="o">=</span> <span class="n">ConFun2</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="n">fParameters</span> <span class="o">=</span> <span class="p">[</span><span class="n">eq</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">distribution</span><span class="o">=</span><span class="s1">&#39;uniform&#39;</span><span class="p">,</span> <span class="n">lower</span><span class="o">=-</span><span class="mf">1.</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)]</span>
<span class="n">myBasis</span> <span class="o">=</span> <span class="n">eq</span><span class="o">.</span><span class="n">Basis</span><span class="p">(</span><span class="s1">&#39;total-order&#39;</span><span class="p">)</span>
<span class="n">fpoly</span> <span class="o">=</span> <span class="n">eq</span><span class="o">.</span><span class="n">Poly</span><span class="p">(</span><span class="n">fParameters</span><span class="p">,</span> <span class="n">myBasis</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;compressive-sensing&#39;</span><span class="p">,</span> <span class="n">sampling_args</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;mesh&#39;</span><span class="p">:</span> <span class="s1">&#39;user-defined&#39;</span><span class="p">,</span> <span class="s1">&#39;sample-points&#39;</span><span class="p">:</span><span class="n">X</span><span class="p">,</span> <span class="s1">&#39;sample-outputs&#39;</span><span class="p">:</span><span class="n">f</span><span class="p">})</span>
<span class="n">fpoly</span><span class="o">.</span><span class="n">set_model</span><span class="p">()</span>

<span class="n">g2Parameters</span> <span class="o">=</span> <span class="p">[</span><span class="n">eq</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">distribution</span><span class="o">=</span><span class="s1">&#39;uniform&#39;</span><span class="p">,</span> <span class="n">lower</span><span class="o">=-</span><span class="mf">1.</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)]</span>
<span class="n">myBasis</span> <span class="o">=</span> <span class="n">eq</span><span class="o">.</span><span class="n">Basis</span><span class="p">(</span><span class="s1">&#39;total-order&#39;</span><span class="p">)</span>
<span class="n">g2poly</span> <span class="o">=</span> <span class="n">eq</span><span class="o">.</span><span class="n">Poly</span><span class="p">(</span><span class="n">g2Parameters</span><span class="p">,</span> <span class="n">myBasis</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;compressive-sensing&#39;</span><span class="p">,</span> <span class="n">sampling_args</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;mesh&#39;</span><span class="p">:</span> <span class="s1">&#39;user-defined&#39;</span><span class="p">,</span> <span class="s1">&#39;sample-points&#39;</span><span class="p">:</span><span class="n">X</span><span class="p">,</span> <span class="s1">&#39;sample-outputs&#39;</span><span class="p">:</span><span class="n">g2</span><span class="p">})</span>
<span class="n">g2poly</span><span class="o">.</span><span class="n">set_model</span><span class="p">()</span>

<span class="c1">#Initialise optimization problem by specifying optimisation method</span>
<span class="n">Opt</span> <span class="o">=</span> <span class="n">Optimisation</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;SLSQP&#39;</span><span class="p">)</span>
<span class="c1">#Add objective function by specifying Poly object</span>
<span class="n">Opt</span><span class="o">.</span><span class="n">add_objective</span><span class="p">(</span><span class="n">Poly</span><span class="o">=</span><span class="n">fpoly</span><span class="p">)</span>
<span class="c1">#Add nonlinear inequality constraints lb &lt;= g2poly &lt;= ub</span>
<span class="n">Opt</span><span class="o">.</span><span class="n">add_nonlinear_ineq_con</span><span class="p">(</span><span class="n">poly</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;poly&#39;</span><span class="p">:</span> <span class="n">g2poly</span><span class="p">,</span> <span class="s1">&#39;bounds&#39;</span><span class="p">:</span> <span class="p">[</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span><span class="mf">4.0</span><span class="p">]})</span>
<span class="c1">#Solve optimisation problem</span>
<span class="n">sol2</span> <span class="o">=</span> <span class="n">Opt</span><span class="o">.</span><span class="n">optimise</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">))</span>
<span class="n">xopt2</span> <span class="o">=</span> <span class="n">sol2</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">]</span>
<span class="n">fopt2</span> <span class="o">=</span> <span class="n">sol2</span><span class="p">[</span><span class="s1">&#39;fun&#39;</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">ObjFun2</span><span class="p">(</span><span class="n">xopt2</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">ConFun2</span><span class="p">(</span><span class="n">xopt2</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sol2</span><span class="p">[</span><span class="s1">&#39;nfev&#39;</span><span class="p">])</span>
</pre></div>
</div>
<table class="colwidths-given docutils align-center" id="id2">
<caption><span class="caption-text">Optimisation results</span><a class="headerlink" href="#id2" title="Permalink to this table">¶</a></caption>
<colgroup>
<col style="width: 25%" />
<col style="width: 25%" />
<col style="width: 25%" />
<col style="width: 25%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Optimisation strategy</p></th>
<th class="head"><p>Function evaluations</p></th>
<th class="head"><p>Solution</p></th>
<th class="head"><p>Constraint value</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>COBYLA</p></td>
<td><p>551</p></td>
<td><p>-5.889</p></td>
<td><p>4.0</p></td>
</tr>
<tr class="row-odd"><td><p>Surrogate-based optimisation w/ EQ</p></td>
<td><p>150</p></td>
<td><p>-6.655</p></td>
<td><p>2.134</p></td>
</tr>
</tbody>
</table>
<p>The above table demonstrates the possible benefits of using Effective Quadratures for surrogate-based optimisation, as a better solution is obtained with far fewer function evaluations. It should be noted that the effectiveness of this approach is highly dependent on the accuracy of the surrogate models. In this rather contrived example, orthogonal polynomials defined over the domain of interest provide a very good approximation of the true function; however, in many other cases, this is not necessarily true. In these cases, we can use the <code class="code docutils literal notranslate"><span class="pre">trust-region</span></code> method within the <code class="code docutils literal notranslate"><span class="pre">Optimisation</span></code> class for bound-constrained optimisation problems.</p>
</div>


    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
    </p>
    <p>
        &copy; Copyright 2016-2019 by Effective Quadratures.<br/>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 2.0.1.<br/>
    </p>
  </div>
</footer>
  </body>
</html>