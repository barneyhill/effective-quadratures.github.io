<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>Polynomial surrogate optimisation &#8212;   v8.0 documentation</title>
    <link rel="stylesheet" href="../_static/bootstrap-sphinx.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="../_static/language_data.js"></script>
    <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="shortcut icon" href="../_static/logo.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="prev" title="Embedded Ridge Approximations" href="tutorial_16.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">
<script type="text/javascript" src="../_static/js/jquery-1.11.0.min.js "></script>
<script type="text/javascript" src="../_static/js/jquery-fix.js "></script>
<script type="text/javascript" src="../_static/bootstrap-3.3.7/js/bootstrap.min.js "></script>
<script type="text/javascript" src="../_static/bootstrap-sphinx.js "></script>

  </head><body>

  <div id="navbar" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="index.html"><span><img src="../_static/logo_white_font.png"></span>
           </a>
        <span class="navbar-text navbar-version pull-left"><b>8.0</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="index.html">Explore <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"><ul class="current">
<li class="toctree-l1"><a class="reference internal" href="introduction.html">Effective Quadratures</a><ul>
<li class="toctree-l2"><a class="reference internal" href="introduction.html#code">Code</a></li>
<li class="toctree-l2"><a class="reference internal" href="introduction.html#workshops">Workshops</a></li>
<li class="toctree-l2"><a class="reference internal" href="introduction.html#papers-theory-and-applications">Papers (theory and applications)</a></li>
<li class="toctree-l2"><a class="reference internal" href="introduction.html#get-in-touch">Get in touch</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="team.html">About us</a></li>
<li class="toctree-l1"><a class="reference internal" href="modules.html">Modules</a><ul>
<li class="toctree-l2"><a class="reference internal" href="parameter.html">Parameter</a></li>
<li class="toctree-l2"><a class="reference internal" href="basis.html">Basis</a></li>
<li class="toctree-l2"><a class="reference internal" href="poly.html">Polynomial</a></li>
<li class="toctree-l2"><a class="reference internal" href="subspaces.html">Dimension reduction with polynomials</a></li>
<li class="toctree-l2"><a class="reference internal" href="optimisation.html">Optimisation with polynomials</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="tutorials.html">Tutorials</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="tutorial_1.html">Defining a parameter</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorial_2.html">Generating univariate quadrature rules</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorial_3.html">Constructing orthogonal polynomials</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorial_4.html">Computing moments</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorial_4b.html">Multi-index sets</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorial_5.html">Sparse and tensor grid quadrature rules</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorial_6a.html">Polynomial regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorial_6.html">Polynomial regression for time varying data</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorial_7.html">Polynomial least squares approximations</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorial_8.html">Polynomials via compressive sensing</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorial_9.html">Computing Sobol’ (sensitivity) indices</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorial_9b.html">Higher order Sobol’ indices</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorial_10.html">Nataf transform for correlated inputs</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorial_11.html">Active subspaces with polynomial approximations</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorial_12.html">Polynomial variable projection</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorial_14.html">Vector-valued dimension reduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorial_15.html">Deep learning via polynomials</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorial_16.html">Embedded Ridge Approximations</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Polynomial surrogate optimisation</a></li>
</ul>
</li>
</ul>
</ul>
</li>
              
            
            
            
            
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="../search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
    <div class="body col-md-12 content" role="main">
      
  <div class="section" id="polynomial-surrogate-optimisation">
<h1>Polynomial surrogate optimisation<a class="headerlink" href="#polynomial-surrogate-optimisation" title="Permalink to this headline">¶</a></h1>
<p>In this tutorial, we demonstrate how one may perform optimization of orthogonal polynomials constructed in Effective Quadratures. Orthogonal polynomials <span class="math notranslate nohighlight">\(\psi_{i}\)</span> and their derivatives <span class="math notranslate nohighlight">\(\psi_{i}^{(d)}\)</span> may be found using the standard four-term recurrence</p>
<div class="math notranslate nohighlight">
\[\sqrt{\beta_{i+1}} \psi_{i+1}^{(d)} = (r-\alpha_i) \psi_i^{(d)} - \sqrt{\beta_i} \psi_{i-1}^{(d)} + d \psi_i^{(d-1)}\]</div>
<p>for <span class="math notranslate nohighlight">\(d,i \geq 0\)</span> where <span class="math notranslate nohighlight">\(\psi_i^{(d)} \equiv 0\)</span> for <span class="math notranslate nohighlight">\(n &lt; d, n &lt; 0\)</span>. The recurrence coefficients <span class="math notranslate nohighlight">\(\alpha_i, \beta_i\)</span>, whose values are determined by the user-specified distribution of the weight function, indicate the class of orthogonal polynomial <span class="math notranslate nohighlight">\(\psi_{i}\)</span>. Using this recurrence relation, derivatives of all orders may be calculated by Effective Quadratures very efficiently, allowing the user to have easy access to gradient information for optimization of orthogonal polynomials. Effective Quadratures has a built-in <code class="code docutils literal notranslate"><span class="pre">Optimization</span></code> class that will calculate derivatives of orthogonal polynomials and perform optimization using the <a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html">minimize</a> method from <a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/optimize.html">Scipy optimize</a>.</p>
<p>To demonstrate a simple example, we consider the following constrained optimization problem:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{eqnarray}
\min_{x,y}      \quad           &amp; (1-x)^2 + 100(y-x^2)^2        \\
\textrm{ subject to }   &amp; (x-1)^3 - y + 1 \leq 0        \\
                                                &amp; x + y = 2                             \\
                                                &amp; -1 \leq x \leq 1                      \\
                                                &amp; -1 \leq y \leq 1.
\end{eqnarray}\end{split}\]</div>
<p>First, let’s use <code class="code docutils literal notranslate"><span class="pre">Polyreg</span></code> to construct the objective function and the first constraint in terms of Legendre polynomials defined over a total order basis.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">scipy</span> <span class="k">as</span> <span class="nn">sp</span>
<span class="kn">from</span> <span class="nn">equadratures</span> <span class="k">import</span> <span class="o">*</span>

<span class="k">def</span> <span class="nf">ObjFun</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">f</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="n">f</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">optimize</span><span class="o">.</span><span class="n">rosen</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">,:])</span>
    <span class="k">return</span> <span class="n">f</span>

<span class="k">def</span> <span class="nf">ConFun1</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">g</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="n">g</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">-</span><span class="mf">1.0</span><span class="p">)</span><span class="o">**</span><span class="mi">3</span> <span class="o">-</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mf">1.0</span>
    <span class="k">return</span> <span class="n">g</span>

<span class="n">n</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">20</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span>
<span class="c1">#Construct f using Legendre polynomials with a total order basis</span>
<span class="n">f</span> <span class="o">=</span> <span class="n">ObjFun</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">fparam</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">distribution</span><span class="o">=</span><span class="s1">&#39;uniform&#39;</span><span class="p">,</span> <span class="n">lower</span><span class="o">=-</span><span class="mf">1.</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">fParameters</span> <span class="o">=</span> <span class="p">[</span><span class="n">fparam</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)]</span>
<span class="n">myBasis</span> <span class="o">=</span> <span class="n">Basis</span><span class="p">(</span><span class="s1">&#39;total-order&#39;</span><span class="p">)</span>
<span class="n">fpoly</span> <span class="o">=</span> <span class="n">Poly</span><span class="p">(</span><span class="n">fParameters</span><span class="p">,</span> <span class="n">myBasis</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;least-squares&#39;</span><span class="p">,</span> <span class="n">sampling_args</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;sample-points&#39;</span><span class="p">:</span><span class="n">X</span><span class="p">,</span> <span class="s1">&#39;sample-outputs&#39;</span><span class="p">:</span><span class="n">f</span><span class="p">})</span>
<span class="c1">#Construct g1 using Legendre polynomials with a total order basis</span>
<span class="n">g1</span> <span class="o">=</span> <span class="n">ConFun1</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">g1param</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">distribution</span><span class="o">=</span><span class="s1">&#39;uniform&#39;</span><span class="p">,</span> <span class="n">lower</span><span class="o">=-</span><span class="mf">1.</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">g1Parameters</span> <span class="o">=</span> <span class="p">[</span><span class="n">g1param</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)]</span>
<span class="n">myBasis</span> <span class="o">=</span> <span class="n">Basis</span><span class="p">(</span><span class="s1">&#39;total-order&#39;</span><span class="p">)</span>
<span class="n">g1poly</span> <span class="o">=</span> <span class="n">Poly</span><span class="p">(</span><span class="n">g1Parameters</span><span class="p">,</span> <span class="n">myBasis</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;least-squares&#39;</span><span class="p">,</span> <span class="n">sampling_args</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;sample-points&#39;</span><span class="p">:</span><span class="n">X</span><span class="p">,</span> <span class="s1">&#39;sample-outputs&#39;</span><span class="p">:</span><span class="n">g1</span><span class="p">})</span>
</pre></div>
</div>
<p>The coefficient of determination (R-squared) value of the fit of both of these functions can be computed via:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">fpoly</span><span class="o">.</span><span class="n">getfitStatistics</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">g1poly</span><span class="o">.</span><span class="n">getfitStatistics</span><span class="p">())</span>
</pre></div>
</div>
<p>Both of these functions give a fit of <span class="math notranslate nohighlight">\(1.0\)</span>, indicating an exact fit.</p>
<div class="figure align-center" id="id1">
<a class="reference internal image-reference" href="../_images/Rosenbrock.png"><img alt="../_images/Rosenbrock.png" src="../_images/Rosenbrock.png" style="width: 581.4px; height: 386.4px;" /></a>
<p class="caption"><span class="caption-text">Figure. Contours of the objective function.</span><a class="headerlink" href="#id1" title="Permalink to this image">¶</a></p>
</div>
<p>Now that the nonlinear functions have been constructed using orthogonal polynomials, we can use <code class="code docutils literal notranslate"><span class="pre">Optimization</span></code> to solve the aforementioned optimization problem.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#Initialise optimization problem by specifying optimization method</span>
<span class="n">Opt</span> <span class="o">=</span> <span class="n">Optimization</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;trust-constr&#39;</span><span class="p">)</span>
<span class="c1">#Add objective function by specifying Poly object</span>
<span class="n">Opt</span><span class="o">.</span><span class="n">add_objective</span><span class="p">(</span><span class="n">poly</span><span class="o">=</span><span class="n">fpoly</span><span class="p">)</span>
<span class="c1">#Add nonlinear inequality constraints lb &lt;= g1poly &lt;= ub</span>
<span class="n">Opt</span><span class="o">.</span><span class="n">add_nonlinear_ineq_con</span><span class="p">(</span><span class="n">poly</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;poly&#39;</span><span class="p">:</span> <span class="n">g1poly</span><span class="p">,</span> <span class="s1">&#39;bounds&#39;</span><span class="p">:</span> <span class="p">[</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">]})</span>
<span class="c1">#Add linear equality constraints Ax = b</span>
<span class="n">Opt</span><span class="o">.</span><span class="n">add_linear_eq_con</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">]),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">2.0</span><span class="p">]))</span>
<span class="c1">#Add lower and upper bounds</span>
<span class="n">Opt</span><span class="o">.</span><span class="n">add_bounds</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n</span><span class="p">))</span>
<span class="c1">#Initialize starting point</span>
<span class="n">x0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
<span class="c1">#Solve optimization problem</span>
<span class="n">sol</span> <span class="o">=</span> <span class="n">Opt</span><span class="o">.</span><span class="n">optimize_poly</span><span class="p">(</span><span class="n">x0</span><span class="p">)</span>
</pre></div>
</div>
<p>The above code returns the solution <span class="math notranslate nohighlight">\(-2.13e-14\)</span> found at <span class="math notranslate nohighlight">\(x = [1,1]\)</span>, which very closely responds to the true optimal solution of <span class="math notranslate nohighlight">\(0\)</span>.</p>
<p>Alternatively, if one already has access to function and derivatives and does not want to construct a <code class="code docutils literal notranslate"><span class="pre">Polyreg</span></code> object for the function, user-provided functions may be supplied to the optimization routine. The following code demonstrates how to do this for the first constraint of the same optimization problem.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">ConFun1</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">g</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="n">g</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">-</span><span class="mf">1.0</span><span class="p">)</span><span class="o">**</span><span class="mi">3</span> <span class="o">-</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mf">1.0</span>
    <span class="k">return</span> <span class="n">g</span>

<span class="k">def</span> <span class="nf">ConFun1_Deriv</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">3.0</span><span class="o">*</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">-</span><span class="mf">1.0</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">])</span>

<span class="k">def</span> <span class="nf">ConFun1_Hess</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">g_Hess</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
    <span class="n">g_Hess</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mf">6.0</span><span class="o">*</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">-</span><span class="mf">1.0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">g_Hess</span>

<span class="c1">#Construct lambda functions of the constraint, its derivative, and its Hessian</span>
<span class="n">g1Func</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="o">-</span><span class="n">ConFun1</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
<span class="n">g1Grad</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="o">-</span><span class="n">ConFun1_Deriv</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
<span class="n">g1Hess</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="o">-</span><span class="n">ConFun1_Hess</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
<span class="c1">#Initialise optimization problem by specifying optimization method</span>
<span class="n">Opt</span> <span class="o">=</span> <span class="n">Optimization</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;trust-constr&#39;</span><span class="p">)</span>
<span class="c1">#Add objective function by specifying Poly object</span>
<span class="n">Opt</span><span class="o">.</span><span class="n">add_objective</span><span class="p">(</span><span class="n">poly</span><span class="o">=</span><span class="n">fpoly</span><span class="p">)</span>
<span class="c1">#Add lower and upper bounds</span>
<span class="n">Opt</span><span class="o">.</span><span class="n">add_bounds</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n</span><span class="p">))</span>
<span class="c1">#Add linear equality constraints Ax = b</span>
<span class="n">Opt</span><span class="o">.</span><span class="n">add_linear_eq_con</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">]),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">2.0</span><span class="p">]))</span>
<span class="c1">#Add nonlinear inequality constraints lb &lt;= g1Func &lt;= ub</span>
<span class="n">Opt</span><span class="o">.</span><span class="n">add_nonlinear_ineq_con</span><span class="p">(</span><span class="n">custom</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;function&#39;</span><span class="p">:</span> <span class="n">g1Func</span><span class="p">,</span> <span class="s1">&#39;jac_function&#39;</span><span class="p">:</span> <span class="n">g1Grad</span><span class="p">,</span> <span class="s1">&#39;hessFunction&#39;</span><span class="p">:</span> <span class="n">g1Hess</span><span class="p">)</span>
<span class="c1">#Initialize starting point</span>
<span class="n">x0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
<span class="c1">#Solve optimization problem</span>
<span class="n">sol</span> <span class="o">=</span> <span class="n">Opt</span><span class="o">.</span><span class="n">optimize_poly</span><span class="p">(</span><span class="n">x0</span><span class="p">)</span>
</pre></div>
</div>
<p>The above code returns the solution <span class="math notranslate nohighlight">\(4.76e-14\)</span> found at <span class="math notranslate nohighlight">\(x = [1,1]\)</span>.</p>
<p>The main benefit of using Effective Quadratures for optimization is best realized in cases where derivatives are not known a priori or are very expensive to calculate. Such situations are commonplace in the scientific community e.g. for ‘black-box’ functions whose values are obtained through the use of expensive computer simulations. Derivative-free optimization strategies, such as stochastic optimization or trust-region methods, may be used in such situations; however, the number of function evaluations required may be prohibitively high in some cases. On the other hand, using Effective Quadratures, one can readily construct surrogate models of the function of interest using orthogonal polynomials and then optimize over the surrogate to approximate the optimal solution.</p>
<p>To demonstrate this, we consider the following constrained optimization problem:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{eqnarray}
\min_{x,y}      \quad           &amp; (1-x)^2 + 100(y-x^2)^2        \\
\textrm{ subject to }   &amp; x^2 + y^2 \leq 2.
\end{eqnarray}\end{split}\]</div>
<p>Although, the gradients of these functions can be easily calculated analytically, we will show that if a derivative-free optimization strategy is used, the number of function evaluations can be prohibitively high.</p>
<p>The new constraint can be defined using the following</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">ConFun2</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">g</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="n">g</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span>
    <span class="k">return</span> <span class="n">g</span>
</pre></div>
</div>
<p>and using <a class="reference external" href="https://en.wikipedia.org/wiki/COBYLA">COBYLA</a> (a very common derivative-free optimization strategy), we can find a solution to this optimization problem using the following code:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">constraints</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="s1">&#39;ineq&#39;</span><span class="p">,</span> <span class="s1">&#39;fun&#39;</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">ConFun2</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span> <span class="o">-</span> <span class="mf">2.0</span><span class="p">}</span>
<span class="n">sol2</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">optimize</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">ObjFun</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)),</span> <span class="n">x0</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;COBYLA&#39;</span><span class="p">,</span> <span class="n">constraints</span><span class="o">=</span><span class="n">constraints</span><span class="p">)</span>
</pre></div>
</div>
<p>On the other hand, we can use Effective Quadratures to construct accurate surrogates and optimize over these surrogates using the following code:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#Construct Poly object of constraint</span>
<span class="n">g2</span> <span class="o">=</span> <span class="n">ConFun2</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">g2param</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">distribution</span><span class="o">=</span><span class="s1">&#39;uniform&#39;</span><span class="p">,</span> <span class="n">lower</span><span class="o">=-</span><span class="mf">1.</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">g2Parameters</span> <span class="o">=</span> <span class="p">[</span><span class="n">g2param</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)]</span>
<span class="n">myBasis</span> <span class="o">=</span> <span class="n">Basis</span><span class="p">(</span><span class="s1">&#39;total-order&#39;</span><span class="p">)</span>
<span class="n">g2poly</span> <span class="o">=</span> <span class="n">Poly</span><span class="p">(</span><span class="n">g2Parameters</span><span class="p">,</span> <span class="n">myBasis</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;least-squares&#39;</span><span class="p">,</span> <span class="n">sampling_args</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;sample-points&#39;</span><span class="p">:</span><span class="n">X</span><span class="p">,</span> <span class="s1">&#39;sample-outputs&#39;</span><span class="p">:</span><span class="n">g2</span><span class="p">})</span>

<span class="c1">#Initialise optimization problem by specifying optimization method</span>
<span class="n">Opt</span> <span class="o">=</span> <span class="n">Optimization</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;trust-constr&#39;</span><span class="p">)</span>
<span class="c1">#Add objective function by specifying Poly object</span>
<span class="n">Opt</span><span class="o">.</span><span class="n">add_objective</span><span class="p">(</span><span class="n">Poly</span><span class="o">=</span><span class="n">fpoly</span><span class="p">)</span>
<span class="c1">#Add nonlinear inequality constraints lb &lt;= g2poly &lt;= ub</span>
<span class="n">Opt</span><span class="o">.</span><span class="n">add_nonlinear_ineq_con</span><span class="p">(</span><span class="n">poly</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;poly&#39;</span><span class="p">:</span> <span class="n">g2poly</span><span class="p">,</span> <span class="s1">&#39;bounds&#39;</span><span class="p">:</span> <span class="p">[</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span><span class="mf">2.0</span><span class="p">]})</span>
<span class="c1">#Initialize starting point</span>
<span class="n">x0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
<span class="c1">#Solve optimization problem</span>
<span class="n">sol</span> <span class="o">=</span> <span class="n">Opt</span><span class="o">.</span><span class="n">optimize_poly</span><span class="p">(</span><span class="n">x0</span><span class="p">)</span>
</pre></div>
</div>
<table class="colwidths-given docutils align-center" id="id2">
<caption><span class="caption-text">Optimization results</span><a class="headerlink" href="#id2" title="Permalink to this table">¶</a></caption>
<colgroup>
<col style="width: 33%" />
<col style="width: 33%" />
<col style="width: 33%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Optimization strategy</p></th>
<th class="head"><p>Function evaluations</p></th>
<th class="head"><p>Solution</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>COBYLA</p></td>
<td><p>990</p></td>
<td><p>0.011</p></td>
</tr>
<tr class="row-odd"><td><p>Surrogate-based optimisation</p></td>
<td><p>20</p></td>
<td><p>5.04e-13</p></td>
</tr>
</tbody>
</table>
<p>The above table demonstrates the possible benefits of using Effective Quadratures for surrogate-based optimization, as a better solution is obtained with fewer function evaluations. It should be noted that the effectiveness of this approach is highly dependent on the accuracy of the surrogate models. In this rather contrived example, orthogonal polynomials defined over the domain of interest provide a very good approximation of the true function; however, in many other cases, this is not necessarily true. To mitigate this, Effective Quadratures may be coupled with a trust-region method to construct local polynomial approximations, thereby increasing the accuracy in smaller regions of interest.</p>
</div>


    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
    </p>
    <p>
        &copy; Copyright 2016-2019 by Effective Quadratures.<br/>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 2.0.1.<br/>
    </p>
  </div>
</footer>
  </body>
</html>